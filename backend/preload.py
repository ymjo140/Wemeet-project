import sys
import os

# ğŸŒŸ [í•µì‹¬] ì‹œìŠ¤í…œ ê²½ë¡œ ìë™ ì„¤ì • (Import Error ë°©ì§€)
# í˜„ì¬ íŒŒì¼(preload.py)ì´ ìˆëŠ” í´ë”(backend)ë¥¼ íŒŒì´ì¬ ê²€ìƒ‰ ê²½ë¡œì— ê°•ì œ ì¶”ê°€í•©ë‹ˆë‹¤.
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

import time
import random
import requests
import re
import numpy as np
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from typing import List, Tuple

# ğŸŒŸ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    import models
    from database import Base, DATABASE_URL
    from constants import NAVER_SEARCH_ID, NAVER_SEARCH_SECRET, NAVER_MAP_ID, NAVER_MAP_SECRET
except ImportError as e:
    print(f"âŒ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("ğŸ‘‰ 'backend' í´ë” ì•ˆì— 'models.py', 'database.py', 'constants.py'ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# --- ì„¤ì • ---
SEARCH_API_URL = "https://openapi.naver.com/v1/search/local.json"
GEOCODE_API_URL = "https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode"

# DB ì—°ê²°
try:
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
    print("ğŸ‘‰ .env íŒŒì¼ì˜ DATABASE_URLì´ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ğŸŒŸ [ì „ì²´ í‚¤ì›Œë“œ]
TARGET_KEYWORDS_DICT = {
    "í•œì‹": ["í•œì‹", "í•œì •ì‹", "ì†¥ë°¥", "ê°ˆë¹„", "ë¶ˆê³ ê¸°", "ë³´ìŒˆ", "í•œìš°"],
    "ì–‘ì‹": ["ì–‘ì‹", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "ë¸ŒëŸ°ì¹˜", "ì´íƒˆë¦¬ì•ˆ", "ë‡¨ë¼", "ë¼ìëƒ", "ì•„ë©”ë¦¬ì¹¸", "ì´íƒœë¦¬"],
    "ì¼ì‹": ["ì¼ì‹", "ìŠ¤ì‹œ", "ë¼ë©˜", "ëˆì¹´ì¸ ", "ëˆê¹ŒìŠ¤", "ìš°ë™", "ê°€ì´ì„¸í‚¤", "ì˜¤ë§ˆì¹´ì„¸", "ì´ìì¹´ì•¼", "ì¼ì‹ì½”ìŠ¤", "í›„í† ë§ˆí‚¤"],
    "ì¤‘ì‹": ["ì¤‘ì‹", "ì¤‘êµ­ìš”ë¦¬", "ì§œì¥ë©´", "ì§¬ë½•", "íƒ•ìˆ˜ìœ¡", "ì¤‘ì‹ë‹¹", "ì½”ìŠ¤ìš”ë¦¬", "ë”¤ì„¬", "í› ê¶ˆ"],
    "ì‹ì‚¬ë¯¸íŒ…": ["ë£¸ì‹ë‹¹", "í•œì •ì‹", "ì¼ì‹ì½”ìŠ¤", "í˜¸í…”ë‹¤ì´ë‹", "ì¡°ìš©í•œì‹ë‹¹", "ì ‘ëŒ€ì¥ì†Œ"],
    "ìˆ ": ["ì´ìì¹´ì•¼", "ì™€ì¸ë°”", "ìœ„ìŠ¤í‚¤ë°”", "í”„ë¼ì´ë¹—ë£¸"],
    "ì»¤í”¼ì±—": ["í˜¸í…”ë¼ìš´ì§€", "ì¡°ìš©í•œì¹´í˜", "ë¹„ì¦ˆë‹ˆìŠ¤ì¹´í˜", "ëŒ€í˜•ì¹´í˜", "ë¡œìŠ¤í„°ë¦¬"],
    "íšŒì˜": ["íšŒì˜ì‹¤", "ë¯¸íŒ…ë£¸", "ì„¸ë¯¸ë‚˜ì‹¤", "ê³µê°„ëŒ€ì—¬", "ìŠ¤í˜ì´ìŠ¤í´ë¼ìš°ë“œ", "ì‰ì–´ì‡", "ë¹„ì¦ˆë‹ˆìŠ¤ì„¼í„°", "ê³µìœ ì˜¤í”¼ìŠ¤"],
    "ì›Œí¬ìƒµ": ["íŒŒí‹°ë£¸", "ê³µê°„ëŒ€ì—¬", "ì›Œí¬ìƒµì¥ì†Œ", "ìŠ¤íŠœë””ì˜¤", "ì•„ì›Œí”Œë ˆì´ìŠ¤", "ë ŒíƒˆìŠ¤íŠœë””ì˜¤", "ì„¸ë¯¸ë‚˜ì‹¤"],
    "ë¬¸í™”ìƒí™œ": ["ì˜í™”ê´€", "ë¯¸ìˆ ê´€", "ë°•ë¬¼ê´€", "ì „ì‹œíšŒ", "ê³µì—°ì¥", "ì—°ê·¹", "ë®¤ì§€ì»¬", "ì•„íŠ¸ì„¼í„°", "ê°¤ëŸ¬ë¦¬", "ì¶•ì œ"],
    "ì˜í™”ê´€": ["CGV", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ë©”ê°€ë°•ìŠ¤", "ë…ë¦½ì˜í™”ê´€", "ìë™ì°¨ê·¹ì¥", "ê·¹ì¥"],
    "ì „ì‹œíšŒ": ["ë¯¸ìˆ ê´€", "ë°•ë¬¼ê´€", "ê°¤ëŸ¬ë¦¬", "ì „ì‹œ", "íŒì—…ìŠ¤í† ì–´", "ì†Œí’ˆìƒµ"],
    "ì•¡í‹°ë¹„í‹°": ["ë°©íƒˆì¶œ", "ë³´ë“œê²Œì„ì¹´í˜", "ë³¼ë§ì¥", "ì˜¤ë½ì‹¤", "VRì²´í—˜", "ë§Œí™”ì¹´í˜", "ë…¸ë˜ë°©", "ê³µë°©", "ì›ë°ì´í´ë˜ìŠ¤"],
    "ë°©íƒˆì¶œ": ["ë°©íƒˆì¶œ", "ë°©íƒˆì¶œì¹´í˜", "ì´ìŠ¤ì¼€ì´í”„", "ë¹„íŠ¸í¬ë¹„ì•„", "í‚¤ì´ìŠ¤ì¼€ì´í”„"],
    "ì¡°ìš©í•œ": ["ë£¸ì‹ë‹¹", "í”„ë¼ì´ë¹—", "ì¹¸ë§‰ì´", "ë°©ìŒ", "ì¡°ìš©í•œì¹´í˜"],
    "ì£¼ì°¨": ["ì£¼ì°¨ê°€ëŠ¥", "ë°œë ›íŒŒí‚¹", "ë¬´ë£Œì£¼ì°¨"],
    "ê³ ê¸‰ì§„": ["íŒŒì¸ë‹¤ì´ë‹", "í˜¸í…”", "ì˜¤ë§ˆì¹´ì„¸"],
    "ê°€ì„±ë¹„": ["ì €ë ´í•œ", "ì°©í•œê°€ê²©", "ë¬´í•œë¦¬í•„"]
}

# ğŸŒŸ [ì „ì²´ ì§€ì—­]
TARGET_REGIONS = [
    "ì„œìš¸ì—­", "ì‹œì²­", "ì¢…ê°", "ì¢…ë¡œ3ê°€", "ì¢…ë¡œ5ê°€", "ë™ëŒ€ë¬¸", "ë™ë¬˜ì•", "ì‹ ì„¤ë™", "ì œê¸°ë™",
    "ì²­ëŸ‰ë¦¬", "íšŒê¸°", "ìš©ì‚°", "ë…¸ëŸ‰ì§„", "ì˜ë“±í¬", "ì‹ ë„ë¦¼", "êµ¬ë¡œ", "ë¶€ì²œ", "ë¶€í‰", "ì•ˆì–‘", "ìˆ˜ì›",
    "ê°•ë‚¨", "ì—­ì‚¼", "ì‹ ë…¼í˜„", "ì‚¼ì„±", "ì ì‹¤", "ê±´ëŒ€ì…êµ¬", "ì„±ìˆ˜", "ì™•ì‹­ë¦¬", "ì„ì§€ë¡œ3ê°€", "ì„ì§€ë¡œì…êµ¬",
    "í™ëŒ€ì…êµ¬", "í•©ì •", "ì‹ ì´Œ", "ì´ëŒ€", "ë‹¹ì‚°", "êµ¬ë¡œë””ì§€í„¸ë‹¨ì§€", "ì‹ ë¦¼", "ì‚¬ë‹¹", "ì„œì´ˆ", "êµëŒ€",
    "ì—°ì‹ ë‚´", "ë¶ˆê´‘", "ê²½ë³µê¶", "ì•ˆêµ­", "ì¶©ë¬´ë¡œ", "ì•½ìˆ˜", "ì˜¥ìˆ˜", "ì••êµ¬ì •", "ì‹ ì‚¬", "ê³ ì†í„°ë¯¸ë„", "ì–‘ì¬", "ìˆ˜ì„œ",
    "ë…¸ì›", "ì°½ë™", "ì„±ì‹ ì—¬ëŒ€ì…êµ¬", "í˜œí™”", "ëª…ë™", "íšŒí˜„", "ì‚¼ê°ì§€", "ì´ì´Œ", "ì´ìˆ˜", "ê³¼ì²œ", "ë²”ê³„",
    "ê¹€í¬ê³µí•­", "ì—¬ì˜ë„", "ê³µë•", "ê´‘í™”ë¬¸", "ì²­êµ¬", "êµ°ì", "ì²œí˜¸", "ì˜¬ë¦¼í”½ê³µì›",
    "ì´íƒœì›", "í•œê°•ì§„", "ì•ˆì•”", "ê³ ë ¤ëŒ€", "ì„ê³„", "ë§ì›",
    "ê°•ë‚¨êµ¬ì²­", "ë…¼í˜„", "ë‚´ë°©", "ê°€ì‚°ë””ì§€í„¸ë‹¨ì§€", "ì² ì‚°", "ìƒë´‰",
    "ì•”ì‚¬", "ì„ì´Œ", "ê°€ë½ì‹œì¥", "ë¬¸ì •", "ëª¨ë€",
    "ë§ˆê³¡ë‚˜ë£¨", "ì„ ì •ë¦‰", "ë´‰ì€ì‚¬", "ì¢…í•©ìš´ë™ì¥",
    "íŒêµ", "ë¶„ë‹¹", "ì¼ì‚°", "ì†¡ë„", "ì˜ì •ë¶€"
]

class Preloader:
    def __init__(self):
        self.db = SessionLocal()

    def get_coordinates(self, address: str) -> Tuple[float, float]:
        if not NAVER_MAP_ID: return 0.0, 0.0
        headers = { "X-NCP-APIGW-API-KEY-ID": NAVER_MAP_ID, "X-NCP-APIGW-API-KEY": NAVER_MAP_SECRET }
        try:
            resp = requests.get(GEOCODE_API_URL, headers=headers, params={"query": address})
            if resp.status_code == 200:
                data = resp.json()
                if data.get("addresses"):
                    return float(data["addresses"][0]["y"]), float(data["addresses"][0]["x"])
        except: pass
        return 0.0, 0.0

    def clean_html(self, text):
        return re.sub('<[^<]+?>', '', text)

    def analyze_attributes(self, title, category):
        """ë„¤ì´ë²„ ì¹´í…Œê³ ë¦¬ + ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ ë§¤ì¹­"""
        tags = set()
        price = 2
        
        cats = category.split(">")
        for c in cats:
            c = c.strip()
            if c: tags.add(c)
        
        category_clean = category.replace(">", " ").strip()
        
        # ë©”ì¸ ì¹´í…Œê³ ë¦¬ ê²°ì •
        final_cat = "restaurant"
        if any(k in category_clean for k in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"]): final_cat = "cafe"
        elif any(k in category_clean for k in ["ìˆ ì§‘", "ì£¼ì ", "ì´ìì¹´ì•¼", "ë°”", "í˜¸í”„", "í¬ì°¨"]): final_cat = "pub"; price = 3
        elif any(k in category_clean for k in ["ìŠ¤í„°ë””", "ë…ì„œì‹¤", "ì˜¤í”¼ìŠ¤", "íšŒì˜", "ê³µê°„ëŒ€ì—¬"]): final_cat = "workspace"
        
        # ìƒì„¸ í‚¤ì›Œë“œ ë§¤ì¹­
        for key, keywords in TARGET_KEYWORDS_DICT.items():
            for kw in keywords:
                if kw in title or kw in category_clean:
                    tags.add(kw)
                    tags.add(key)
        
        return final_cat, list(tags)

    def save_to_db(self, item, lat, lng):
        title = self.clean_html(item['title'])
        
        # ì¤‘ë³µ ì²´í¬ (ì´ë¦„ + ì¢Œí‘œ 50m ë°˜ê²½)
        existing = self.db.query(models.Place).filter(models.Place.name == title).all()
        for ex in existing:
            if abs(ex.lat - lat) < 0.0005 and abs(ex.lng - lng) < 0.0005:
                return # ì¤‘ë³µ

        category_raw = item.get('category', '')
        final_cat, tags = self.analyze_attributes(title, category_raw)
        
        address = item.get('roadAddress') or item.get('address') or ""
        
        new_place = models.Place(
            name=title,
            category=final_cat,
            address=address,
            lat=lat,
            lng=lng,
            tags=tags,
            wemeet_rating=round(random.uniform(3.5, 5.0), 1),
            external_link=item.get('link')
        )
        self.db.add(new_place)
        try:
            self.db.commit()
            print(f"  âœ… ì €ì¥: {title} ({final_cat})")
        except Exception as e:
            self.db.rollback()

    def run(self):
        all_keywords = list(set([k for sublist in TARGET_KEYWORDS_DICT.values() for k in sublist]))
        print(f"ğŸš€ [ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘] ì§€ì—­: {len(TARGET_REGIONS)}ê°œ / í‚¤ì›Œë“œ: {len(all_keywords)}ê°œ")
        
        total_saved = 0
        
        for region in TARGET_REGIONS:
            print(f"\nğŸ“ [{region}] íƒìƒ‰ ì¤‘...")
            
            # API ì¿¼í„° ì ˆì•½ì„ ìœ„í•´ ê° ì§€ì—­ë³„ë¡œ í‚¤ì›Œë“œë¥¼ ëœë¤í•˜ê²Œ 5ê°œì”©ë§Œ ë½‘ì•„ì„œ ê²€ìƒ‰í•˜ê±°ë‚˜,
            # ì „ì²´ë¥¼ ëŒë¦¬ë ¤ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” ì „ì²´ ë¦¬ìŠ¤íŠ¸ ì¤‘ ëŒ€í‘œ 5ê°œë§Œ ì˜ˆì‹œë¡œ ë•ë‹ˆë‹¤)
            # ë§Œì•½ ì „ì²´ë¥¼ ë‹¤ ëŒë¦¬ê³  ì‹¶ìœ¼ë©´ below listë¥¼ all_keywordsë¡œ ë°”ê¾¸ì„¸ìš”.
            # í•˜ì§€ë§Œ 25,000ê±´ ì œí•œ ë•Œë¬¸ì— 'ë§›ì§‘', 'ì¹´í˜', 'ìˆ ì§‘' ê°™ì€ ëŒ€í‘œ í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ëŒë¦¬ëŠ” ê²Œ ì•ˆì „í•©ë‹ˆë‹¤.
            
            search_keywords = ["ë§›ì§‘", "ì¹´í˜", "ìˆ ì§‘", "ë†€ê±°ë¦¬", "ìŠ¤í„°ë””ì¹´í˜"] 
            
            for keyword in search_keywords:
                query = f"{region} {keyword}"
                try:
                    headers = { "X-Naver-Client-Id": NAVER_SEARCH_ID, "X-Naver-Client-Secret": NAVER_SEARCH_SECRET }
                    resp = requests.get(SEARCH_API_URL, headers=headers, params={"query": query, "display": 5, "sort": "comment"}, timeout=3)
                    
                    if resp.status_code != 200: continue
                    items = resp.json().get('items', [])
                    
                    for item in items:
                        addr = item.get('roadAddress') or item.get('address')
                        if not addr: continue
                        lat, lng = self.get_coordinates(addr)
                        if lat == 0.0: continue
                        
                        self.save_to_db(item, lat, lng)
                        total_saved += 1
                    
                    time.sleep(0.05) 
                except Exception as e:
                    print(f"Error: {e}")
        
        print(f"\nâœ¨ ì´ {total_saved}ê°œ ì¥ì†Œ ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    models.Base.metadata.create_all(bind=engine)
    loader = Preloader()
    loader.run()